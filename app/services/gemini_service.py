"""Google Gemini AI service for text generation."""

import asyncio
import logging
import re
from typing import Dict, Any, Optional, List
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold

from app.core.config import Settings
from app.core.prompts import get_prompt
from app.core.exceptions import (
    GeminiRateLimitError,
    GeminiQuotaExceededError,
    GeminiAPIError,
    GeminiConfigurationError
)

logger = logging.getLogger(__name__)


class GeminiService:
    """é«˜é€Ÿãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®ãŸã‚ã®Google Gemini AIã‚µãƒ¼ãƒ“ã‚¹ã€‚"""
    
    def __init__(self, settings: Settings):
        """Geminiã‚µãƒ¼ãƒ“ã‚¹ã‚’åˆæœŸåŒ–ã™ã‚‹ã€‚
        
        Args:
            settings: APIã‚­ãƒ¼ã‚’å«ã‚€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
        """
        self.settings = settings
        self._configure_gemini()
        self.model = self._create_model()
    
    def _configure_gemini(self) -> None:
        """APIã‚­ãƒ¼ã¨å®‰å…¨è¨­å®šã§Geminiã‚’è¨­å®šã™ã‚‹ã€‚"""
        if not self.settings.gemini_api_key:
            raise GeminiConfigurationError("GEMINI_API_KEY environment variable is required")
        
        genai.configure(api_key=self.settings.gemini_api_key)
        logger.info("Gemini API configured successfully")
    
    def _create_model(self) -> genai.GenerativeModel:
        """é«˜é€Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”¨ã«æœ€é©åŒ–ã•ã‚ŒãŸGeminiãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹ã€‚
        
        Returns:
            genai.GenerativeModel: è¨­å®šæ¸ˆã¿ã®Geminiãƒ¢ãƒ‡ãƒ«
        """
        # Use Gemini 2.0 Flash for fast response
        model = genai.GenerativeModel(
            model_name="gemini-2.0-flash-exp",
            generation_config=genai.types.GenerationConfig(
                temperature=0.7,  # Balanced creativity and consistency
                top_p=0.8,       # Focus on high-probability tokens
                top_k=40,        # Limit token choices for faster response
                max_output_tokens=1024,  # Limit output length for speed
                stop_sequences=[],
            ),
            safety_settings={
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            }
        )
        logger.info("Gemini model created with fast response configuration")
        return model
    
    def _parse_api_error(self, error: Exception) -> Exception:
        """Gemini APIã‚¨ãƒ©ãƒ¼ã‚’è§£æã—ã€é©åˆ‡ãªã‚«ã‚¹ã‚¿ãƒ ä¾‹å¤–ã‚’è¿”ã™ã€‚
        
        Args:
            error: Gemini APIã‹ã‚‰ã®å…ƒã®ä¾‹å¤–
            
        Returns:
            Exception: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŒã¤ã‚«ã‚¹ã‚¿ãƒ ä¾‹å¤–
        """
        error_str = str(error)
        
        # Rate limit error (429)
        if "429" in error_str and "quota" in error_str.lower():
            # Extract retry delay if available
            retry_match = re.search(r'retry_delay.*?seconds: (\d+)', error_str)
            retry_seconds = int(retry_match.group(1)) if retry_match else None
            
            # Check if it's free tier rate limit
            if "FreeTier" in error_str:
                message = f"â±ï¸ Gemini APIç„¡æ–™æ ã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚{retry_seconds}ç§’å¾Œã«å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚"
                # Don't log as warning since it's expected behavior for free tier
                logger.info(f"Rate limit reached (free tier): retry in {retry_seconds}s")
                return GeminiRateLimitError(message, retry_seconds)
            else:
                message = f"â±ï¸ APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚{retry_seconds}ç§’å¾Œã«å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚"
                logger.info(f"Rate limit reached: retry in {retry_seconds}s")
                return GeminiRateLimitError(message, retry_seconds)
        
        # Quota exceeded error
        if "quota" in error_str.lower() and "exceeded" in error_str.lower():
            message = "ğŸ“Š APIã®æœˆé–“åˆ©ç”¨åˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚Gemini APIã®ãƒ—ãƒ©ãƒ³ã‚’ã”ç¢ºèªãã ã•ã„ã€‚"
            logger.warning("Quota exceeded - consider upgrading API plan")
            return GeminiQuotaExceededError(message)
        
        # Generic API error
        if "400" in error_str or "500" in error_str:
            status_match = re.search(r'(\d{3})', error_str)
            status_code = int(status_match.group(1)) if status_match else None
            message = "APIæ¥ç¶šã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚"
            logger.error(f"API error {status_code}: {error_str}")
            return GeminiAPIError(message, status_code)
        
        # Unknown error
        logger.error(f"Unknown error: {error_str}")
        return GeminiAPIError("äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
    
    def _should_log_error(self, error: Exception) -> bool:
        """ã‚¨ãƒ©ãƒ¼ã®ç¨®é¡ã«åŸºã¥ã„ã¦ãƒ­ã‚°ã‚’å‡ºåŠ›ã™ã‚‹ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹ã€‚
        
        Args:
            error: ãƒã‚§ãƒƒã‚¯å¯¾è±¡ã®ä¾‹å¤–
            
        Returns:
            bool: ã‚¨ãƒ©ãƒ¼ã‚’ãƒ­ã‚°ã«å‡ºåŠ›ã™ã‚‹å ´åˆã¯True
        """
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã¯ç„¡æ–™æ ã§ã¯æƒ³å®šå†…ã®ã‚¨ãƒ©ãƒ¼ãªã®ã§ãƒ­ã‚°å‡ºåŠ›ã—ãªã„
        if isinstance(error, GeminiRateLimitError):
            return False
        
        # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ã¯ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹
        return True
    
    async def generate_text(
        self,
        prompt: str,
        system_prompt: Optional[str] = None,
        **kwargs: Any
    ) -> str:
        """é«˜é€Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚’ä½¿ç”¨ã—ã¦Geminiã§ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚
        
        Args:
            prompt: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            system_prompt: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”¨ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            **kwargs: è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        
        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãƒ¬ã‚¹ãƒãƒ³ã‚¹
        
        Raises:
            GeminiRateLimitError: ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’è¶…éã—ãŸå ´åˆ
            GeminiQuotaExceededError: ã‚¯ã‚©ãƒ¼ã‚¿ã‚’è¶…éã—ãŸå ´åˆ
            GeminiAPIError: APIãŒã‚¨ãƒ©ãƒ¼ã‚’è¿”ã—ãŸå ´åˆ
            ValueError: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒç©ºã®å ´åˆ
        """
        try:
            # Combine system and user prompts
            full_prompt = self._build_full_prompt(system_prompt, prompt)
            
            logger.debug(f"Generating text with prompt length: {len(full_prompt)}")
            
            # Generate content asynchronously
            response = await asyncio.to_thread(
                self.model.generate_content,
                full_prompt
            )
            
            if not response.text:
                raise ValueError("Empty response from Gemini")
            
            logger.info("Text generated successfully")
            return response.text.strip()
            
        except Exception as e:
            # Parse and raise appropriate custom exception
            custom_error = self._parse_api_error(e)
            
            # Only log if it's a significant error
            if self._should_log_error(custom_error):
                logger.error(f"Failed to generate text: {str(e)}")
            
            raise custom_error
    
    async def generate_learning_plan(
        self,
        goal: str,
        time_available: int,
        current_level: str = "ä¸­ç´š",
        focus_areas: Optional[List[str]] = None,
        difficulty: str = "medium"
    ) -> str:
        """äº‹å‰å®šç¾©ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¦å­¦ç¿’ãƒ—ãƒ©ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ã€‚
        
        Args:
            goal: å­¦ç¿’ç›®æ¨™
            time_available: åˆ©ç”¨å¯èƒ½æ™‚é–“ï¼ˆåˆ†ï¼‰
            current_level: ç¾åœ¨ã®ã‚¹ã‚­ãƒ«ãƒ¬ãƒ™ãƒ«
            focus_areas: é‡ç‚¹åˆ†é‡
            difficulty: é›£æ˜“åº¦
        
        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸå­¦ç¿’ãƒ—ãƒ©ãƒ³
        """
        system_prompt = get_prompt("learning_plan", "system")
        user_prompt = get_prompt("learning_plan", "user_template").format(
            goal=goal,
            time_available=time_available,
            current_level=current_level,
            focus_areas=", ".join(focus_areas) if focus_areas else "æŒ‡å®šãªã—",
            difficulty=difficulty
        )
        
        return await self.generate_text(user_prompt, system_prompt)
    
    async def generate_todo_list(
        self,
        time_available: int,
        recent_progress: Optional[str] = None,
        weak_areas: Optional[List[str]] = None,
        daily_goal: Optional[str] = None
    ) -> str:
        """æ—¥æ¬¡TODOãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚
        
        Args:
            time_available: åˆ©ç”¨å¯èƒ½æ™‚é–“ï¼ˆåˆ†ï¼‰
            recent_progress: æœ€è¿‘ã®å­¦ç¿’é€²æ—
            weak_areas: æ”¹å–„ãŒå¿…è¦ãªåˆ†é‡
            daily_goal: ä»Šæ—¥ã®å…·ä½“çš„ãªç›®æ¨™
        
        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸTODOãƒªã‚¹ãƒˆ
        """
        system_prompt = get_prompt("todo", "system")
        user_prompt = get_prompt("todo", "user_template").format(
            time_available=time_available,
            recent_progress=recent_progress or "ãƒ‡ãƒ¼ã‚¿ãªã—",
            weak_areas=", ".join(weak_areas) if weak_areas else "ç‰¹ã«ãªã—",
            daily_goal=daily_goal or "åŠ¹æœçš„ãªå­¦ç¿’"
        )
        
        return await self.generate_text(user_prompt, system_prompt)
    
    async def analyze_progress(
        self,
        period: str,
        learning_records: str,
        goals: str,
        progress_rate: float
    ) -> str:
        """å­¦ç¿’é€²æ—ã‚’åˆ†æã™ã‚‹ã€‚
        
        Args:
            period: åˆ†ææœŸé–“
            learning_records: å­¦ç¿’è¨˜éŒ²ãƒ‡ãƒ¼ã‚¿
            goals: å­¦ç¿’ç›®æ¨™
            progress_rate: ç¾åœ¨ã®é€²æ—ç‡
        
        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸåˆ†æçµæœ
        """
        system_prompt = get_prompt("analysis", "system")
        user_prompt = get_prompt("analysis", "user_template").format(
            period=period,
            learning_records=learning_records,
            goals=goals,
            progress_rate=progress_rate
        )
        
        return await self.generate_text(user_prompt, system_prompt)
    
    async def give_advice(
        self,
        current_issues: str,
        learning_status: str,
        concerns: Optional[str] = None,
        target_goal: Optional[str] = None
    ) -> str:
        """å­¦ç¿’ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã™ã‚‹ã€‚
        
        Args:
            current_issues: ç¾åœ¨ã®å­¦ç¿’èª²é¡Œ
            learning_status: ç¾åœ¨ã®å­¦ç¿’çŠ¶æ³
            concerns: å…·ä½“çš„ãªæ‡¸å¿µäº‹é …
            target_goal: ç›®æ¨™
        
        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸã‚¢ãƒ‰ãƒã‚¤ã‚¹
        """
        system_prompt = get_prompt("advice", "system")
        user_prompt = get_prompt("advice", "user_template").format(
            current_issues=current_issues,
            learning_status=learning_status,
            concerns=concerns or "ç‰¹ã«ãªã—",
            target_goal=target_goal or "å­¦ç¿’ã®æ”¹å–„"
        )
        
        return await self.generate_text(user_prompt, system_prompt)
    
    async def set_goals(
        self,
        desired_outcome: str,
        timeline: str,
        current_level: str,
        available_resources: str,
        constraints: Optional[str] = None
    ) -> str:
        """SMARTç›®æ¨™ã‚’ç”Ÿæˆã™ã‚‹ã€‚
        
        Args:
            desired_outcome: å¸Œæœ›ã™ã‚‹å­¦ç¿’æˆæœ
            timeline: ç›®æ¨™ã®æœŸé™
            current_level: ç¾åœ¨ã®ã‚¹ã‚­ãƒ«ãƒ¬ãƒ™ãƒ«
            available_resources: åˆ©ç”¨å¯èƒ½ãªãƒªã‚½ãƒ¼ã‚¹
            constraints: åˆ¶ç´„æ¡ä»¶
        
        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸSMARTç›®æ¨™
        """
        system_prompt = get_prompt("goal", "system")
        user_prompt = get_prompt("goal", "user_template").format(
            desired_outcome=desired_outcome,
            timeline=timeline,
            current_level=current_level,
            available_resources=available_resources,
            constraints=constraints or "ç‰¹ã«ãªã—"
        )
        
        return await self.generate_text(user_prompt, system_prompt)
    
    def _build_full_prompt(self, system_prompt: Optional[str], user_prompt: str) -> str:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’çµåˆã—ã¦ãƒ•ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ã€‚
        
        Args:
            system_prompt: ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            user_prompt: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        
        Returns:
            str: çµåˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        """
        if system_prompt:
            return f"{system_prompt}\n\n{user_prompt}"
        return user_prompt
    
    async def health_check(self) -> Dict[str, Any]:
        """Geminiã‚µãƒ¼ãƒ“ã‚¹ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã€‚
        
        Returns:
            Dict[str, Any]: ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯çµæœ
        """
        try:
            test_response = await self.generate_text("ãƒ†ã‚¹ãƒˆ")
            return {
                "status": "healthy",
                "service": "gemini",
                "model": "gemini-2.0-flash-exp",
                "test_response_length": len(test_response)
            }
        except GeminiRateLimitError as e:
            return {
                "status": "rate_limited",
                "service": "gemini",
                "message": str(e),
                "retry_after_seconds": e.retry_after_seconds
            }
        except Exception as e:
            custom_error = self._parse_api_error(e)
            return {
                "status": "unhealthy",
                "service": "gemini",
                "error": str(custom_error)
            }


# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å…¨ä½“ã§ä½¿ç”¨ã™ã‚‹ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_gemini_service: Optional[GeminiService] = None


def get_gemini_service(settings: Optional[Settings] = None) -> GeminiService:
    """Geminiã‚µãƒ¼ãƒ“ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ã¾ãŸã¯ä½œæˆã™ã‚‹ã€‚
    
    Args:
        settings: åˆæœŸåŒ–ã«ä½¿ç”¨ã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®è¨­å®š
    
    Returns:
        GeminiService: Geminiã‚µãƒ¼ãƒ“ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    """
    global _gemini_service
    
    if _gemini_service is None:
        if settings is None:
            settings = Settings()
        _gemini_service = GeminiService(settings)
    
    return _gemini_service
